{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "prkj3jlx5sws6567ews4",
   "authorId": "6380573264452",
   "authorName": "MAGPIE07",
   "authorEmail": "",
   "sessionId": "2a74358f-943d-48da-936f-4b9155efcf4a",
   "lastEditTime": 1745844059182
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "name": "lab_8_stages_and_semi_structured_data"
   },
   "source": [
    "# Lab 8: Stages and Semi-structured Data\n",
    "\n",
    "## Create a Snowflake Stage Object\n",
    "\n",
    "ðŸ‘‰ In this lesson, we'll create a stage that points to an **S3** (Amazon Simple Storage Service) bucket the Education Services team created for you to use. \n",
    "\n",
    "To begin, let's grab **context information** we will use throughout this lab. \n",
    "\n",
    "- Click the **Start** button to activate this notebook.\n",
    "\n",
    "- Run the following Python cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a6924-a608-4b8d-8d0a-0e296443eb2a",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "#### :warning: Each time a new session is started for this notebook, you need to rerun the cell below to configure \"variables\" for use in later cells. :warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d41b4-9d71-4120-9083-7f23aa53e8e8",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "user = session.get_current_user().strip('\"')\n",
    "your_db = user + '_DB'\n",
    "print('Your current CONTEXT information:')\n",
    "print('---------------------------------')\n",
    "print(session)\n",
    "print('Your current USER is ' + user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14acad33-6bff-4a71-9e80-c66b3994fb04",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": [
    "### Stage creation. ðŸ¥‹\n",
    "\n",
    "1. In the Snowsight Object Browser, select the **(animal)_UTIL_DB** database you created in an earlier lab.\n",
    "1. Then select the schema named **PUBLIC**.\n",
    "1. Click on the blue **Create** button top right.\n",
    "1. Select **Stage** > **External Stage** > **Amazon S3**.\n",
    "\n",
    "![Create stage option (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_create_stage_new_1.png)\n",
    "\n",
    "A stage creation dialog will appear.\n",
    "\n",
    "![Stage creation dialog (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_create_stage_dialog_1.png)\n",
    "\n",
    "1. In the **Stage Name** text box, enter: `like_a_window_into_an_s3_bucket`.\n",
    "1. Enter the following name into the **URL** text box: `s3://uni-lab-files`.\n",
    "1. Ensure that the **Directory table** option remains selected.\n",
    "1. Click the blue **Create** button in the lower right corner.\n",
    "1. The following screen may request the name of a Snowflake Virtual Warehouse to use - choose your named warehouse **(animal)_WH**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5961fd-02f1-4128-87f6-e98f11a3609a",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": [
    "### The Object Browser shows the files available in this new Stage you have created. ðŸ““\n",
    "\n",
    "![Stage files (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_new_stage_files.png)\n",
    "\n",
    "\n",
    "ðŸ’¡ **Tip**: These files and folders are sitting in an AWS S3 bucket that is owned and managed by the Snowflake Education Services team that is providing you with this course. You can see the list of files here because you created a stage, which acts like a window to allow you to see and access the files in that bucket. Our bucket is public, but the buckets your company creates will likely require credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50ce2a-6355-4118-bf88-3a6e33b06ca6",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "### A Stage or Not A Stage? ðŸ““ \n",
    "\n",
    "One weird and confusing thing about stages in Snowflake is that the stage object you created is not a location. The location (the S3 bucket that holds the files) already existed. So, what did you just create? \n",
    "\n",
    "Well, you created something that tells Snowflake some information about a location where some files are already staged. You didn't create the actual stage location; you created something more like a window into that stage location. Your Snowflake stage object is almost like a File Format in that it holds configuration information that makes loading files easier.\n",
    "\n",
    "Sometimes, when we define a Snowflake stage, we also provide access credentials, but in this case, we did not. Our stage is just an object we named that points to an S3 bucket where some files are already staged.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb39a90-a856-46cf-9fd4-dc773664b462",
   "metadata": {
    "collapsed": false,
    "name": "use_the_list_command"
   },
   "source": [
    "## Use the LIST command from a SQL cell ðŸ¥‹ \n",
    "\n",
    "### Use the LIST Command to View the Files in your new Stage ðŸ¥‹ \n",
    "\n",
    "The `LIST` command returns a list of files that have been staged (that is uploaded from a local file system or unloaded from a table) in a Snowflake stage. \n",
    "- This command can also be abbreviated to `LS`.\n",
    "- You refer to a Stage object in Snowflake by its name, prefixed with an ampersand `@` character.\n",
    "\n",
    "Try the following `LIST` command yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050182e1-0cb5-4f9d-82d7-9b1f1bc98d9c",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "USE SCHEMA {{user}}_UTIL_DB.PUBLIC;\n\nLIST @like_a_window_into_an_s3_bucket;"
  },
  {
   "cell_type": "markdown",
   "id": "27333ef9-d29f-4baf-b265-25932ba6cc4f",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "### Snowflake Object naming conventions. ðŸ““\n",
    "\n",
    "Notice that Snowflake doesn't care about capitalization. We entered the name of our new Stage object in lowercase. Snowflake always assumes you really mean to type everything in **UPPER CASE**, so it converts it for you. Because of this, you can type lowercase or mixed case when creating or querying objects, and Snowflake will convert it to all uppercase behind the scenes.\n",
    "\n",
    "(Unless you use quotes when creating things, and then you'll have to use quotes forever after that to deal with the object.)\n",
    "\n",
    "So, when running commands on the Stage, any case spelling will work. However, S3 is very particular, so you must be very disciplined once you get past the Stage Object name. You have to use the exact spelling - with correct cases, even for the file extension.  \n",
    "\n",
    "![Stage files (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_list_command_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac8cbe-1b9d-44c4-aaf0-3b3e243339a0",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "### Check 8 (OB08) ðŸ”Ž\n",
    "\n",
    "- Do you have an external stage created, named `like_a_window_into_an_s3_bucket`?\n",
    "- Call the grading stored procedure to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048865b-e8aa-46b5-9b88-d06cb64ceb41",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "CALL common_db.resources.local_grader('OB08', '{{user}}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2c5a9-8760-4700-a29c-ce6a72f212af",
   "metadata": {
    "collapsed": false,
    "name": "use_the_copy_into_statement"
   },
   "source": [
    "## Use the `COPY INTO` Statement to Load Data ðŸ¥‹ \n",
    "\n",
    "### Create a Table for Soil Types ðŸ¥‹ \n",
    "\n",
    "Make sure you create it in the **(animal)_GARDEN_PLANTS** database, in the **VEGGIES** schema. To do so, you must alter LINE 2 in the following SQL cell, replacing the hash `('#')` characters with the correct schema name, before executing the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f9e1e-538d-450b-a577-6c8d6310cc64",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "-- replace the hash characters ('#') on the next line\nUSE SCHEMA {{user}}_GARDEN_PLANTS.VEGGIES;\n\nCREATE OR REPLACE TABLE vegetable_details_soil_type\n( plant_name VARCHAR(25)\n ,soil_type NUMBER(1,0)\n);"
  },
  {
   "cell_type": "markdown",
   "id": "5b4edb83-c540-4635-9c71-f87457ab955a",
   "metadata": {
    "collapsed": false,
    "name": "cell14"
   },
   "source": [
    "### Load a file from the S3 bucket into the new table. ðŸ““\n",
    "\n",
    "Previously you used the Snowsight **Load Data** screen to copy data from a staged file into a table. When using this \"wizard-driven\" approach Snowflake generates and executes code behind the scenes to perform this action. For this data load, we will explore the programmatic approach.\n",
    "\n",
    "You will use a `COPY INTO` statement, run from within a notebook SQL cell.\n",
    "\n",
    "To use the `COPY INTO` statement, it is best to have four things in place:\n",
    "\n",
    "1. A table \n",
    "\n",
    "1. A stage object\n",
    "\n",
    "1. A file\n",
    "\n",
    "1. A file format (optional)\n",
    "\n",
    "The **file format** is optional because there is an alternative, but it's a cleaner process if you have one. As mentioned earlier, the file format is an object that provides Snowflake with instructions on handling the data being loaded from a stage. In the following example, we will provide these \"instructions\" inline rather than defining a file format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4d8d3-76d6-4144-9e3c-8444bdf6485d",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "### A `Copy Into` statement you can run. ðŸ¥‹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca3120-6e6d-41fb-a140-809318091367",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "COPY INTO vegetable_details_soil_type\n",
    "FROM @{{user}}_util_db.public.like_a_window_into_an_s3_bucket\n",
    "FILES = ( 'VEG_NAME_TO_SOIL_TYPE_PIPE.txt')\n",
    "FILE_FORMAT = (\n",
    "    TYPE=csv\n",
    "    FIELD_DELIMITER = '|'\n",
    "    SKIP_HEADER=1\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a184e68-26b0-4563-b8f5-12de8fa7d321",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "### Check 9 (OB09) ðŸ”Ž\n",
    "\n",
    "- Do you have 42 rows loaded into the **vegetable_details_soil_type** table in the **(animal)_garden_plants.veggies** schema?\n",
    "- Call the grading stored procedure to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d971d-267f-44bf-a614-14d889fc9da8",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "CALL common_db.resources.local_grader('OB09', '{{user}}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f157b44-df8d-4bcb-bcb3-38ca7118f33e",
   "metadata": {
    "collapsed": false,
    "name": "data_loading_tips_and_tricks"
   },
   "source": [
    "## Data Loading Tips and Tricks ðŸ““\n",
    "\n",
    "- All flat files are loaded using file formats that have a type of CSV (Comma Separated Values). So, use `TYPE = CSV` for any flat file (TSV, Pipe Delimited, .txt, and so on).\n",
    "\n",
    "- The **FIELD_DELIMITER** property is very important. It should match the actual Column Separator being used in the file. \n",
    "\n",
    "- The Data Load Wizard can help you write your file format (named or inline). Just choose the settings you need in the drop lists, then click the Show SQL link to access the SQL code for those settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293f9eb-c7f8-46c4-91ee-da56f1b4f0d8",
   "metadata": {
    "collapsed": false,
    "name": "challenge_exercise"
   },
   "source": [
    "## Challenge Exercise: Create a Soil Type Look Up Table ðŸŽ¯ \n",
    "\n",
    "In this challenge exercise, you are going to create a new table named **lu_soil_type** and load it with data from a supplied file in one of the following ways:\n",
    "- using the **Load Data** wizard **OR**\n",
    "- writing your own `COPY INTO` statement and executing this\n",
    "\n",
    ":warning: Only high-level instructions will be supplied for this exercise, and you will be expected to \"figure out the steps\" based on the material we have covered already. :warning:\n",
    "\n",
    "First, set about creating the table. Make sure you create it in the **(animal)_GARDEN_PLANTS** database in the **VEGGIES** schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ebe7f-2229-4e34-b954-2ba31f9d69e5",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "USE SCHEMA {{user}}_GARDEN_PLANTS.VEGGIES;\n",
    "\n",
    "CREATE OR REPLACE TABLE lu_soil_type(\n",
    "    soil_type_id NUMBER,\t\n",
    "    soil_type VARCHAR(15),\n",
    "    soil_description VARCHAR(75)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0403b5e-6166-4bbc-8d22-e00328d82a93",
   "metadata": {
    "collapsed": false,
    "name": "cell22"
   },
   "source": [
    "### Download the source data file. ðŸŽ¯ \n",
    "\n",
    "Run the following Python code cell and click on the link generated to download the **LU_SOIL_TYPE.tsv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fb6eb-0b9b-4167-9838-1d21d8e0f816",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "snowpark_df = session.sql(\"SELECT GET_PRESIGNED_URL(@common_db.resources.course_files, 'LU_SOIL_TYPE.tsv')\")\n",
    "collected_data = snowpark_df.collect()\n",
    "st.write('Click the following link to download the file:')\n",
    "st.write(collected_data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd3939-b9f6-4835-bd9f-1732f3ab7c94",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": [
    "### Load table rows from the downloaded file. ðŸŽ¯\n",
    "\n",
    "The file **LU_SOIL_TYPE.tsv** shares many of the file format properties with the file you loaded previously, **VEG_NAME_TO_SOIL_TYPE_PIPE.txt**, with one major exception. Let's outline these:\n",
    "- **TYPE**: the file has an extension of **.tsv** (so you should be able to figure out it's [type](https://docs.snowflake.com/en/sql-reference/sql/copy-into-table#type-csv)).\n",
    "- **SKIP_HEADER**: the file has one header row.\n",
    "- **FIELD_DELIMITER**: the file **IS NOT** pipe delimited (`'|'`) it is **TAB** delimited, which is represented by the following characters: `'\\t'`.\n",
    "\n",
    "\n",
    "#### Option 1:\n",
    "- Use the **Load Data** wizard in Snowsight.\n",
    "\n",
    "#### OR\n",
    "\n",
    "#### Option 2:\n",
    "- Using the notes above, modify and run the following SQL `COPY INTO` fragment.\n",
    "- Supply the target table name (line 1).\n",
    "- Supply the file format options (lines 5-7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b1aab5-8e23-42b5-a596-a0b287c981df",
   "metadata": {
    "language": "sql",
    "name": "cell25"
   },
   "outputs": [],
   "source": "COPY INTO LU_SOIL_TYPE\nFROM @{{user}}_util_db.public.like_a_window_into_an_s3_bucket\nFILES = ( 'LU_SOIL_TYPE.tsv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER='0x09',\n    TRIM_SPACE=TRUE,\n    FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n);\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "e798ed97-33f5-4e68-bf6b-8f386aba618e",
   "metadata": {
    "collapsed": false,
    "name": "cell26"
   },
   "source": [
    "### Check 10 (OB10) ðŸ”Ž\n",
    "\n",
    "- Do you have 8 rows loaded into the **lu_soil_type** table in the **(animal)_garden_plants.veggies** schema?\n",
    "- Call the grading stored procedure to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070433e-9ae1-446a-9e6c-993123d27280",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell27"
   },
   "outputs": [],
   "source": [
    "CALL common_db.resources.local_grader('OB10', '{{user}}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f03286-acbb-4ab8-a99f-4fce6bbcdc23",
   "metadata": {
    "collapsed": false,
    "name": "work_with_semi_structured_data"
   },
   "source": [
    "## Work with Semi-structured Data ðŸ““\n",
    "\n",
    "Semi-structured data is data that does not conform to the standards of traditional structured data but contains tags (labels) or other types of mark-up that identify individual, distinct entities within the data. Two key attributes that distinguish semi-structured data from structured data are nested data structures and the lack of a fixed schema:\n",
    "\n",
    "- Semi-structured data does not require a prior definition of a schema and can constantly evolve (new attributes can be added at any time).\n",
    "- Unlike structured data, which represents data as a flat table, semi-structured data can contain N-level hierarchies of nested information.\n",
    "\n",
    "Here's an example of JSON data, which is one of the semi-structured types supported by Snowflake.\n",
    "\n",
    "![Vegetable details table data (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_json_data_extract.png)\n",
    "\n",
    "### The `VARIANT` data type.\n",
    "\n",
    "Snowflake offers the [`VARIANT`](https://docs.snowflake.com/en/sql-reference/data-types-semistructured#label-data-type-variant) data type to support the storage of semi-structured data. This is a data type that can hold a value of any other data type, including [`ARRAY`](https://docs.snowflake.com/en/sql-reference/data-types-semistructured#array) and [`OBJECT`](https://docs.snowflake.com/en/sql-reference/data-types-semistructured#object) (which are also often used in conjunction with semi-structured data). Using this data type, we can preserve semi-structured data's hierarchical/nested format when ingesting it to Snowflake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd398a3-1c5c-4c86-b5c1-a3aa622ad5ee",
   "metadata": {
    "collapsed": false,
    "name": "cell29"
   },
   "source": [
    "### Create a table including a `VARIANT` column. ðŸ¥‹\n",
    "\n",
    "Create a table called **VEGETABLE_DETAILS_PLANT_HEIGHT** in the **VEGGIES** schema of the **(animal)_GARDEN_PLANTS** database. This contains a single column - of the `VARIANT` data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e620cc4-3a3a-4db5-9939-7ac80add38fa",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE {{user}}_GARDEN_PLANTS.VEGGIES.VEGETABLE_DETAILS_PLANT_HEIGHT (\n",
    "\trecord VARIANT\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6382ab1-12de-4207-ab43-452c01a232c6",
   "metadata": {
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "### Download the JSON source data file. ðŸ¥‹\n",
    "\n",
    "Run the following Python code cell and click on the link generated to download the JSON **veg_plant_height.json** file.\n",
    "\n",
    "Depending on your browser, this may open directly in a new tab/window or download. If downloaded, open the file in a text editor on your local system to review its structure.\n",
    "\n",
    "ðŸ’¡ **Tip**: You are downloading this file to review its structure and content. When loading the data from this file, we will use the file already located in the stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675948d-8e58-4134-a628-065071b42b6e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": [
    "snowpark_df = session.sql(\"SELECT GET_PRESIGNED_URL(@common_db.resources.course_files, 'veg_plant_height.json')\")\n",
    "collected_data = snowpark_df.collect()\n",
    "st.write('Click the following link to download the file:')\n",
    "st.write(collected_data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfbf33c-bf77-4eec-b492-90af6eeb8c1b",
   "metadata": {
    "collapsed": false,
    "name": "cell33"
   },
   "source": [
    "### A `Copy Into` statement you can run to load JSON data. ðŸ¥‹ \n",
    "\n",
    "Now run the following statement to load this JSON data into your new table.\n",
    "\n",
    "- What has changed in the following **file format** specifications to accommodate the loading of the semi-structured, rather than structured, data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ba29c-75cc-459a-ac41-e4b796a9fe72",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "COPY INTO vegetable_details_plant_height\n",
    "FROM @common_db.resources.course_files/veg_plant_height.json\n",
    "FILE_FORMAT = (TYPE = 'JSON');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcfdcd-5dea-4df4-ab92-20d9aec5223d",
   "metadata": {
    "collapsed": false,
    "name": "cell35"
   },
   "source": [
    "### Query the table loaded from JSON data. ðŸ¥‹\n",
    "\n",
    "Snowflake has special operators and functions to query complex hierarchical data stored in a `VARIANT`. We will introduce those shortly, but for now, let's review a single row of data from the **vegetable_details_plant_height** table using regular SQL syntax of the type we would use against structured data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3021b5-b318-4961-8692-61e36564f27f",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM vegetable_details_plant_height\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d816dd9-9cda-45bc-af74-e87ab933c379",
   "metadata": {
    "collapsed": false,
    "name": "cell37"
   },
   "source": [
    "### Query semi-structured data. \n",
    "\n",
    "What you will have observed in the query above is that the `VARIANT` column named **RECORD** contains a set of four key-pair values. This is fine, with the data retained in the format in which it was ingested. However, there are likely times when you will want to isolate individual elements for processing and use in a structured format for reporting. \n",
    "\n",
    "Here are some high-level guidelines for **traversing** semi-structured data in Snowflake. \n",
    "- Insert a colon `:` between a `VARIANT` column name and any first-level element\n",
    "    - <column>:<level1_element>\n",
    "- Use dot notation to access subsequent elements nested further down the hierarchical path in a JSON object: \n",
    "    - <column>:<level1_element>.<level2_element>.<level3_element>\n",
    "- The **column name** is case-insensitive, but element names **are** case-sensitive.\n",
    "- You can optionally enclose element names in double quotes.\n",
    "\n",
    "Try this simple example to **flatten** (which means to represent as structured data) the rows in the **vegetable_details_plant_height** table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92345cd9-b2dc-40ee-9b3b-2fd1c248cc4d",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell38"
   },
   "outputs": [],
   "source": [
    "//Returns the data in a way that makes it look like a normalized table\n",
    "SELECT \n",
    "    record:PLANT_NAME::STRING AS plant_name,\n",
    "    record:UOM AS uom, -- no casting \n",
    "    record:LOW_END_OF_RANGE::INTEGER AS low_end_of_range,\n",
    "    record:HIGH_END_OF_RANGE::INTEGER AS high_end_of_range\n",
    "FROM vegetable_details_plant_height;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079120f-fad7-44b7-bee9-37a8a4357466",
   "metadata": {
    "collapsed": false,
    "name": "cell39"
   },
   "source": [
    "### Casting `VARIANT` values. ðŸ““\n",
    "\n",
    "What you may have noticed when running the query above was that the **UOM** column values were not **cast** (converted to other datatypes) like the others, so they looked slightly different. They were wrapped in double quotes, like this: \"F\".\n",
    "\n",
    "This does not mean the column values are `VARCHAR` or `STRING` (its synonym); instead, it indicates that it is still a `VARIANT` value. The `VARIANT` values are not strings; rather, the `VARIANT` values contain strings.\n",
    "\n",
    "In Snowflake SQL, you can cast datatypes from one to another in the following ways:\n",
    "- using the [`CAST()`](https://docs.snowflake.com/en/sql-reference/functions/cast) function\n",
    "- using the `::` operator as an alternative syntax (e.g. **record:PLANT_NAME::STRING**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f9589-31b8-42ff-8ea5-a09dfd1aebc5",
   "metadata": {
    "collapsed": false,
    "name": "challenge_exercise_2"
   },
   "source": [
    "## Challenge Exercise: Create a View to Showcase Semi-structured Data ðŸŽ¯ \n",
    "\n",
    "In this challenge exercise you are going to create a new [View](https://docs.snowflake.com/en/user-guide/views-introduction) object. A View allows the result of a query to be accessed as if it were a table. The aim is to present the data in the **vegetable_details_plant_height** in a normalized fashion.\n",
    "\n",
    "1. Modify the scaffolded SQL in the cell below - the three lines requiring changes have been identified with `-- ***`.\n",
    "1. **CAST** the **UOM** column to `VARCHAR`.\n",
    "1. **SWAP** the order of the **LOW_END_OF_RANGE** and **HIGH_END_OF_RANGE** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06aade-7ad0-4480-8d49-9a00d6399179",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell41"
   },
   "outputs": [],
   "source": "-- modify the following code according to the instructions above, then run to create the object\nCREATE OR REPLACE VIEW vegetable_details_plant_height_vw AS \nSELECT \n    record:PLANT_NAME::STRING AS plant_name,\n    cast(record:UOM AS VARCHAR) as UOM, -- *** \n    record:HIGH_END_OF_RANGE::INTEGER AS high_end_of_range, -- ***\n    record:LOW_END_OF_RANGE::INTEGER AS low_end_of_range -- ***\n    \nFROM vegetable_details_plant_height;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47418956-54f7-4604-b09b-2fb57b42a6fc",
   "metadata": {
    "language": "sql",
    "name": "cell42"
   },
   "outputs": [],
   "source": [
    "-- then run this query against your new view to confirm the output\n",
    "SELECT *\n",
    "FROM vegetable_details_plant_height_vw;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054da240-9b64-4bac-9b5b-76dc772df3e0",
   "metadata": {
    "collapsed": false,
    "name": "cell43"
   },
   "source": [
    "### Check 11 (OB11) ðŸ”Ž\n",
    "\n",
    "- Have you created a view named **vegetable_details_plant_height_vw** in the **VEGGIES** schema of the **(animal)_GARDEN_PLANTS** database?\n",
    "- Has the **UOM** been cast to a `VARCHAR` (text) column, with the **HIGH_END_OF_RANGE** column in the third position and **LOW_END_OF_RANGE** fourth?\n",
    "- Call the grading stored procedure to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b693fe-11fe-4bd0-a7bd-7177189c3c51",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "CALL common_db.resources.local_grader('OB11', '{{user}}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949499da-e79b-4638-aac1-937286d97f87",
   "metadata": {
    "collapsed": false,
    "name": "test_your_knowledge"
   },
   "source": [
    "## Test Your Knowledge. :mag_right:\n",
    "\n",
    "Run the following Python cell to present a Streamlit-driven widget and answer the question about the Snowflake interfaces. You don't have to understand what this is doing for now. Just go ahead and run the code.\n",
    "\n",
    "You need to answer these questions correctly to proceed to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81586a60-61f1-4519-b533-0fbf735ecc0f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell46"
   },
   "outputs": [],
   "source": [
    "st.divider()\n",
    "question = \"Why do you think we gave our Snowflake Stage Object the name LIKE_A_WINDOW_INTO_AN_S3_BUCKET?\"\n",
    "options = [\"Pick selection below...\",\n",
    "           \"A) Because it is short so it is easy to type\", \n",
    "           \"B) Because stages are easy to break, like windows can sometimes be\", \n",
    "           \"C) Because \\\"stage\\\" sounds like a location, and in this case, the location is the S3 bucket, not the Snowflake object we created\"]                                 \n",
    "\n",
    "user_answer = st.radio(question, options, index=0)\n",
    "if user_answer:\n",
    "    if user_answer == \"Pick selection below...\": # this option is a workaround until streamlit is upgraded > 1.26.0 so we can use index=None\n",
    "        ''\n",
    "    else:\n",
    "        answer = '6f74543483f45510df0587c869a7262a'\n",
    "        response = session.sql(f\"call common_db.resources.quiz_temp('{answer}', '{user_answer}', 'False')\").collect()\n",
    "        if response:\n",
    "            value = response[0]['QUIZ_TEMP']\n",
    "        st.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c87712-629d-4b11-b67c-1e628d054b58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell47"
   },
   "outputs": [],
   "source": [
    "st.divider()\n",
    "question = \"UPPER CASE, lower case, miXEd CaSe? Who cares? Which of the statements below are true about Snowflake's case sensitivity?\"\n",
    "options = [\"Pick selection below...\",\n",
    "           \"A) Snowflake assumes you always meant to type UPPER_CASE, unless you put something in double-quotes\", \n",
    "           \"B) If you create a table called HAPPY Snowflake will actually name it happy\", \n",
    "           \"C) If you create a table called \\\"hAppY\\\", every time you query it, you will need to put it in single quotes\"]                                 \n",
    "\n",
    "user_answer = st.radio(question, options, index=0)\n",
    "if user_answer:\n",
    "    if user_answer == \"Pick selection below...\": # this option is a workaround until streamlit is upgraded > 1.26.0 so we can use index=None\n",
    "        ''\n",
    "    else:\n",
    "        answer = '2728d9093f1996db9b951aabec1b02f1'\n",
    "        response = session.sql(f\"call common_db.resources.quiz_temp('{answer}', '{user_answer}', 'False')\").collect()\n",
    "        if response:\n",
    "            value = response[0]['QUIZ_TEMP']\n",
    "        st.write(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2fec6-5051-468f-bbcd-2db4a2d2ba1b",
   "metadata": {
    "collapsed": false,
    "name": "next_steps"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "If you have completed the lab steps and answered the **Knowledge Test** questions correctly, please proceed to the next Notebook when advised by your Snowflake instructor."
   ]
  }
 ]
}