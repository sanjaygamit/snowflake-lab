{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "kz4vhii62g5dxa4h2e2n",
   "authorId": "6380573264452",
   "authorName": "MAGPIE07",
   "authorEmail": "",
   "sessionId": "35d007a8-3627-403c-8d15-dee42801ed2b",
   "lastEditTime": 1745847315817
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "name": "lab_9_unstructured_data"
   },
   "source": [
    "# Lab 9: Unstructured Data and Cortex LLM Functions\n",
    "\n",
    "ðŸ‘‰ In this lesson we'll review PDF documents that have been supplied, and make use of a Snowflake Cortex function to parse these documents, and write the information to a table. A second Cortex function will be employed to label (or classify) the rows of data in the table. We will construct an analytical query and the visualize this using Streamlit to show the breakdown of information across categories. And, finally we will take a quick tour through the capabilities of three other Cortex functions. \n",
    "\n",
    "To begin, let's grab **context information** we will use throughout this lab. \n",
    "\n",
    "- Click the **Start** button to activate this notebook.\n",
    "\n",
    "- Run the following Python cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79e10f-eb2e-4edc-b268-6356cc782f71",
   "metadata": {
    "name": "cell2"
   },
   "source": [
    "#### :warning: Each time a new session is started for this notebook, you need to rerun the cell below to configure \"variables\" for use in later cells. :warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e712ce-273e-471c-acec-f6d717afe2ea",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "user = session.get_current_user().strip('\"')\n",
    "session.use_database(f'{user}_GARDEN_PLANTS')\n",
    "session.use_schema('VEGGIES')\n",
    "print('Your current CONTEXT information:')\n",
    "print('---------------------------------')\n",
    "print(session)\n",
    "print('Your current USER is ' + user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ade07-278c-47f8-a7df-5ec3a5352f9b",
   "metadata": {
    "collapsed": false,
    "name": "work_with_unstructured_data"
   },
   "source": [
    "## Work with Unstructured Data in Snowflake ðŸ““\n",
    "\n",
    "In previous sections of this course, we examined both structured data (think rows and columns) and semi-structured data (think JSON format). Snowflake also includes features and functions for working with [**unstructured data**](https://docs.snowflake.com/en/user-guide/unstructured-intro), which analysts predict will make up 80% of the world's data by the year 2025.\n",
    "\n",
    "So, what is it exactly?\n",
    "\n",
    "**Unstructured data** is information that does not fit into a predefined data model or schema. Typically text-heavy, such as form responses and social media conversations, unstructured data also encompasses images, video, and audio. Industry-specific file types such as VCF (genomics), KDF (semiconductors), or HDF5 (aeronautics) are included in this category.\n",
    "\n",
    "The Snowflake AI Data Cloud can help access, share, and process **unstructured data** files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2700572-5539-45c6-a1ae-58e9d3aa4f7e",
   "metadata": {
    "collapsed": false,
    "name": "an_unstructured_data_scenario"
   },
   "source": [
    "## An Unstructured Data Scenario ðŸ““\n",
    "\n",
    "Just imagine for a moment that over time you have collected dozens of interesting facts and details about the plants you enjoy tending and exported these \"snippets\" of information as PDF files on your laptop. Wouldn't it be great to find a way to bring that data into Snowflake to use it alongside the information you have already built out?\n",
    "\n",
    "This is precisely the scenario we will work through in the exercises in this lab. You will:\n",
    "1. Parse the information from staged PDF files using a Cortex LLM function.\n",
    "1. Extract and ingest the data to a new table in Snowflake.\n",
    "1. Explore Snowflake Cortex LLM functions to analyze and generate using this data. :robot_face:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fcb861-b31f-4837-9afb-5b7d4e0fa6bd",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "### Produce a listing of the supplied PDF files. ðŸ¥‹\n",
    "\n",
    "A collection of ~130 PDF files containing interesting facts and details about plants has been uploaded to **course_files** stage in **common_db.resources** for you by the Education Services team.\n",
    "\n",
    "**Modify** the SQL following code extract below and **run the cell** to `LIST` the supplied PDF files in the designated stage:\n",
    "- Replace the hash `(#)` characters with the appropriate command and syntax to build the correct SQL statement.\n",
    "- Run the SQL cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1ee6d-7cfd-4922-840d-aea727f00c2b",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "LIST @common_db.resources.course_files/garden_kb"
  },
  {
   "cell_type": "markdown",
   "id": "9543d151-99bc-4e9a-bd4a-fc5c13599c1d",
   "metadata": {
    "collapsed": false,
    "name": "directory_tables"
   },
   "source": [
    "## Directory Tables ðŸ““\n",
    "\n",
    "When working with unstructured data, **directory tables** are really helpful, and in many ways superior to working with the `LIST` command.\n",
    "\n",
    "A [directory table](https://docs.snowflake.com/en/user-guide/data-load-dirtables) is an implicit object layered on a stage (not a separate database object) and is conceptually similar to an external table because it stores file-level metadata about the data files in the stage. Both internal and external stages are supported. The great thing is that these objects enable us to query the contents of a directory as if it were a table! The process of creating a directory table is as simple as enabling the option during the creation of a stage or altering the stage after creation. \n",
    "\n",
    "- In fact, you created a directory table back in Lab 8, though you may not have even realized it, as it is a default option included when using the Snowsight wizard to create a stage object.\n",
    "\n",
    "\n",
    "You can access the directory table output with a table function, and pass names and file locations with ease to various Snowflake functions for processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12d62c-a925-401b-bef4-2a09d00c9a1d",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "### Query a directory table. ðŸ¥‹\n",
    "\n",
    "Take a look at the structure of the following query:\n",
    "- It is a regular `SELECT` statement.\n",
    "- Note the use of the **DIRECTORY** keyword to access the table function.\n",
    "- We can choose columns to return `*` (\"star all\") in this case.\n",
    "- We can also filter our results (as we do to only return those files under the \"garden_kb\" subdirectory of this stage).\n",
    "\n",
    "Run this query and review the output, noting the types of information it returns about the files contained in this stage location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a933c74-2cf6-4337-9ca9-a15e36fff0be",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "SELECT *    \n",
    "FROM DIRECTORY('@common_db.resources.course_files')\n",
    "WHERE CONTAINS(relative_path, 'garden_kb/');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d902de0-7ecf-4e56-82b3-0ccafcb60d13",
   "metadata": {
    "collapsed": false,
    "name": "review_the_supplied_pdf_files"
   },
   "source": [
    "## Review the supplied PDF files. ðŸ¥‹\n",
    "\n",
    "### What gardening insights have been collected?\n",
    "\n",
    "As mentioned earlier, a collection of ~130 PDF files containing interesting facts and details about plants has been uploaded for you by the Education Services team.\n",
    "\n",
    "- The collection of PDF files is named **snippet_1.pdf** through **snippet_129.pdf**. \n",
    "\n",
    "You might be interested to know what sort of information these \"factoid\" files contain!\n",
    "\n",
    "Here's an example from this PDF file collection of plant and gardening knowledge. The text comes from the first file in the collection and relates to **artichokes**.\n",
    "\n",
    "Growing **artichokes**? Some good tips here!\n",
    "\n",
    "![snippet sample (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_artichokes_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2dd224-0eb2-46f6-9862-c1ada706bd67",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "### Download one of the plant \"factoid\" PDF files and review. ðŸ““\n",
    "\n",
    "You have seen an example of the content in a PDF file in our plant and gardening knowledge collection above. But let's download and open another PDF file and review.\n",
    "\n",
    "- In the following example, we will examine the file: **snippet_9.pdf**.\n",
    "\n",
    "- The SQL code (embedded inside Python) in this example makes use of a Snowflake function that generates links to files stored in stages, that can even be accessed \"outside\" of Snowflake. This is helpful when working with **unstructured** data. Please refer to the Snowflake documentation to learn more about the [GET_PRESIGNED_URL](https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url) function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ff49c-182d-430f-ae59-be6c8b5775bb",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": [
    "### Run the following Python code cell and use the link generated to download the file. ðŸ¥‹\n",
    "\n",
    "**Right-click** on the link generated and **Open** in new tab or browser window (clicking the link will NOT work).\n",
    "\n",
    "**Open** the file in a PDF viewer application on your local machine if not opened automatically in your browser.\n",
    "\n",
    "- Let's see what nuggets of information are in this PDF file about your favorite veggie - Asparagus! :leafy_green:\n",
    "\n",
    "- Feel free to examine some of the other files, numbered 1 through 129, after working through the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf7d40a-d2b5-4fdf-842b-0acf20b33c3b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "snowpark_df = session.sql(\"SELECT GET_PRESIGNED_URL(@common_db.resources.course_files, 'garden_kb/snippet_9.pdf')\")\n",
    "collected_data = snowpark_df.collect()\n",
    "st.write('Open the following link in a new browser tab or window and review.')\n",
    "st.write(collected_data[0][0])\n",
    "st.write('Asparagus. Who knew!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d0270-6a08-4565-929d-b9559a4fcca8",
   "metadata": {
    "collapsed": false,
    "name": "introducing_snowflake_cortex_ai"
   },
   "source": [
    "## Introducing Snowflake Cortex AI ðŸ““\n",
    "\n",
    "The Snowflake AI Data Cloud contains a suite of features and functions that give you instant access to industry-leading large language models (LLMs) trained by researchers at companies like Mistral, Reka, Meta, and Google, including Snowflake Arctic, an open enterprise-grade model developed by Snowflake.\n",
    "\n",
    "Since these LLMs are fully hosted and managed by Snowflake, using them requires **NO SETUP**. Your data stays within Snowflake, giving you the performance, scalability, and governance you expect.\n",
    "\n",
    "ðŸ’¡ Please refer to the Snowflake documentation for the [release status and availability](https://docs.snowflake.com/en/guides-overview-ai-features) of the following features.\n",
    "\n",
    "![Snowflake generative AI (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_gen_ai_1.png)\n",
    "\n",
    "### Snowflake Cortex LLM functions.\n",
    "\n",
    "One subset of the Snowflake AI options available is **Cortex LLM functions**. These are provided as SQL functions and are also available in Python, making accessing their powerful capabilities easy!\n",
    "\n",
    "Cortex LLM Functions can be grouped into the following categories:\n",
    "\n",
    "- Task-specific functions\n",
    "\n",
    "- Helper functions\n",
    "\n",
    "- `COMPLETE` function\n",
    "\n",
    "ðŸ‘‰ We will work some of these functions to ingest and \"process\" our plant and gardening data in the remainder of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fda02-7449-40e8-aea1-d47a9dacb0bb",
   "metadata": {
    "collapsed": false,
    "name": "utilize_parse_document"
   },
   "source": [
    "## Utilize `PARSE_DOCUMENT()` to Extract Text ðŸ““\n",
    "\n",
    "Cortex [parse_document()](https://docs.snowflake.com/user-guide/snowflake-cortex/parse-document) is a Cortex LLM task-specific function that provides the ability to extract text or layout from documents stored in an internal or external stage. \n",
    "\n",
    "It is a SQL function. Because it is fully hosted and managed by Snowflake, using it requires no setup. This means you simply point the `PARSE_DOCUMENT` function to a stage where PDF documents are stored to extract text or layout data. In short, all it requires is:\n",
    "\n",
    "- The name of a stage to read from.\n",
    "\n",
    "- The PDF document within that stage you want to extract text from (it only supports PDF files at this point).\n",
    "\n",
    "- It can read document layouts, but we will select the **OCR** mode to work with, which is great for handling text extraction.\n",
    "\n",
    "ðŸ’¡ **Tip**: for even more sophisticated document extraction use cases you might want to check out the **LAYOUT** mode of this function or review Snowflake's [Document AI](https://docs.snowflake.com/en/user-guide/snowflake-cortex/document-ai/overview) service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d10b8-f8ed-4cb0-8d0e-b32f59a68d53",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "### Text extraction example. ðŸ¥‹\n",
    "\n",
    "Review the following SQL statement:\n",
    "\n",
    "- It uses a fully-qualified reference to the `PARSE_DOCUMENT()` function.\n",
    "\n",
    "- We have provided a reference to the PDF document stage and a single file within that (this is the \"Asparagus\" example you opened earlier).\n",
    "\n",
    "It's that easy. All you are doing is calling this \"built-in\" SQL function, and behind the scenes, Snowflake will open and read the file content and return it.\n",
    "\n",
    "Go ahead and run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10f281-e5e0-41dc-8c82-c5d77a2ca2ae",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT (\n",
    "        @common_db.resources.course_files,\n",
    "        'garden_kb/snippet_9.pdf',\n",
    "        {'mode': 'OCR'}\n",
    "    ) AS output;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aba6b2-526d-4c51-954f-a500f989c0f8",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "### Review the `PARSE_DOCUMENT()` output. ðŸ¥‹\n",
    "\n",
    "Notice that the output from this function is provided in a semi-structured data format:\n",
    "\n",
    "![Parse_document() output (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_parse_document_1.png)\n",
    "\n",
    "There are **content** and **metadata** fields. \n",
    "\n",
    "ðŸ’¡ **Tip**:  remember, as you learned in **Lab 8**, that we can drill down into the nested fields contained within these semi-structured data structures using the `:` operator!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e76936-1153-4871-8276-7a6da8503499",
   "metadata": {
    "collapsed": false,
    "name": "build_a_text_extraction_workflow"
   },
   "source": [
    "## Build a Text Extraction Workflow ðŸ““\n",
    "\n",
    "Now that we have a method to extract the text from the supplied plant and gardening PDF documents, we want to bring it into Snowflake so that we can use it.\n",
    "\n",
    "ðŸ‘‰ We want to create a **knowledge base** out of all the plant and gardening information that we have collected, and we can see many potential uses for this data.\n",
    "\n",
    "Here is the workflow:\n",
    "\n",
    "- Our knowledge base information begins as **UNSTRUCTURED** data in PDF files.\n",
    "\n",
    "- The Cortex `PARSE_DOCUMENT()` function is run to extract the text from the PDF files and into a **SEMI-STRUCTURED** data format.\n",
    "\n",
    "- Using Snowflake's syntax we can parse the output from the Cortex function to return **STRUCTURED** data content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f795da7-c1cf-41c1-a602-42059c353456",
   "metadata": {
    "collapsed": false,
    "name": "cell21"
   },
   "source": [
    "### Create a table to hold the knowledge base data. ðŸ¥‹ \n",
    "\n",
    "First, we need to create a table to hold the reference information extracted from the PDF documents.\n",
    "\n",
    "Go ahead and run the following code to do so in the **(animal)_GARDEN_PLANTS.VEGGIES** schema. Note that we will include a column for the plant's name, which the content in the PDF file refers to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361962b9-5842-40f6-b3ec-4b3ac626fee2",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE vegetable_knowledge_base (\n",
    "    source_document STRING, -- the document name\n",
    "    insight STRING,         -- the \"factoid\" contained with the file\n",
    "    plant_name STRING       -- the name of the plant the \"factoid\" references\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1c96a-fb74-45dd-90f0-6f887e5c8056",
   "metadata": {
    "collapsed": false,
    "name": "cell23"
   },
   "source": [
    "### Extract then `INSERT` data into the new table. ðŸ¥‹\n",
    "\n",
    "Let's begin bringing some of the features and functions we have learned about in this lab together.\n",
    "\n",
    "The following `INSERT` statement leverages **directory tables** and the `PARSE_DOCUMENT()` function \n",
    "\n",
    "- The **directory table** listing returns the name of each of our PDF files in the **garden_kb** subdirectory of the **common_db.resources.course_files** stage.\n",
    "\n",
    "- The location of each PDF document is passed to the `PARSE_DOCUMENT()` function so that text is extracted.\n",
    "\n",
    "- Extracted text is returned in a semi-structured format and the **content** element is isolated and cast to a `STRING` with: `:content::STRING as extract`.\n",
    "\n",
    "**Run** the code below to write the file name and extracted text for each PDF file to your new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98dd04-5928-463d-a8f8-6d56c5c00ec7",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell24"
   },
   "outputs": [],
   "source": [
    "INSERT INTO vegetable_knowledge_base (source_document, insight)\n",
    "    SELECT \n",
    "        split_part(relative_path,'/',-1) as file_name, \n",
    "        SNOWFLAKE.CORTEX.PARSE_DOCUMENT (\n",
    "            @common_db.resources.course_files,\n",
    "            relative_path,\n",
    "            {'mode': 'OCR'}\n",
    "        ):content::STRING as extract    \n",
    "    from directory('@common_db.resources.course_files')\n",
    "    where contains(relative_path, 'garden_kb/')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5e511-cad9-4893-a4d1-f9f52afe646a",
   "metadata": {
    "collapsed": false,
    "name": "cell25"
   },
   "source": [
    "### Check your work. ðŸŽ¯\n",
    "\n",
    "**129** rows should be inserted into your new table. Now take a look at the \"shape\" of this data in the table.\n",
    "\n",
    "- **Rewrite** the following query fragment to return **all** rows from your new knowledge base table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2009de-304d-47b2-bfe1-6f8e1c920688",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": "SELECT *\nFROM vegetable_knowledge_base"
  },
  {
   "cell_type": "markdown",
   "id": "0c7c4c8a-29b0-406f-b82e-0ddb9f2022f8",
   "metadata": {
    "collapsed": false,
    "name": "cell27"
   },
   "source": [
    "### We have a problem!\n",
    "\n",
    "We have managed to extract data from the supplied PDF files and write this to a table, but here is a problem...\n",
    "\n",
    "Without reviewing the content of the **INSIGHT** column, we can't tell which plant each row of information relates to. All of the **PLANT_NAME** columns are empty. That's a problem when implementing a knowledge base!\n",
    "\n",
    "We _could_ read each row and update the **PLANT_NAME** column manually, but that will take a long time with 129 rows in this table - and it's untenable with a much larger data set.\n",
    "\n",
    "![Knowledge base table 1 (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_kb_table_query_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa2347-e0da-4b45-8f6d-d963ac5baf02",
   "metadata": {
    "collapsed": false,
    "name": "utilize_classify_text"
   },
   "source": [
    "## Utilize `CLASSIFY_TEXT()` on Text You Have Extracted ðŸ““\n",
    "\n",
    "Thankfully, Snowflake Cortex includes an LLM function called [CLASSIFY_TEXT()](https://docs.snowflake.com/en/sql-reference/functions/classify_text-snowflake-cortex). As its name suggests, this classifies free-form text data you provide.\n",
    "\n",
    "- It is straightforward to invoke from SQL and, like the other Cortex LLM functions, doesn't require any setup - it's included as part of the Snowflake offering.\n",
    "\n",
    "- The function returns a string that contains a JSON object. The JSON object contains the category that the input prompt was classified as. If invalid arguments are given, an error is returned.\n",
    "\n",
    "![Classify text usage (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_classify_text_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef37a51-57ec-4b29-9122-28f6be2f68fd",
   "metadata": {
    "collapsed": false,
    "name": "cell29"
   },
   "source": [
    "### Classification example. ðŸ¥‹\n",
    "\n",
    "Review the following example that relates to our use case. We are passing the input string **apple** to the Cortex LLM function to review and, hopefully, categorize correctly as a **fruit**, **veggie**, or **flower**.\n",
    "\n",
    "Go ahead and run the following code.\n",
    "\n",
    "- Was it accurate?\n",
    "\n",
    "- Try it with **tomato** as an input. :grinning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bab2e8-36d8-42fc-b920-97705606df9b",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": "SELECT SNOWFLAKE.CORTEX.CLASSIFY_TEXT('onions', ['fruit', 'veggies', 'flowers']);"
  },
  {
   "cell_type": "markdown",
   "id": "df41db05-2414-4455-9cd2-9e6a56c35aba",
   "metadata": {
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "### An expanded classification use case. ðŸ““\n",
    "\n",
    "This is GREAT! This means we don't have to manually update the 129 rows in our table - we can have Snowflake do the heavy lifting.\n",
    "\n",
    "- We need to write an `UPDATE` statement. \n",
    "\n",
    "- For each row in the table we pass the **INSIGHT** column as input.\n",
    "\n",
    "- We can construct a list of names of all the known plants we store references to from the **VEGETABLE_DETAILS** table, which was created and loaded in an earlier lab.\n",
    "\n",
    "- We can drill down into the semi-structured data output to extract the label value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135c239-4a6c-4055-9410-c266160e5b8f",
   "metadata": {
    "collapsed": false,
    "name": "cell32"
   },
   "source": [
    "### Run classification. ðŸ¥‹\n",
    "\n",
    "Review the following SQL statement:\n",
    "\n",
    "- It uses a fully-qualified reference to the `CLASSIFY_TEXT()` function.\n",
    "\n",
    " - The syntax in **LINE 6** may be new to you, but all this is doing is creating an `ARRAY` of plant names from the **vegetable_details** table to pass to the Cortex LLM function\n",
    "    - this saves time rather than typing `Artichoke...Zucchini` manually!\n",
    "\n",
    "Go ahead and run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028ce52-67af-4fa3-8466-fb07a15a6e52",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "UPDATE vegetable_knowledge_base\n",
    "SET plant_name = SNOWFLAKE.CORTEX.CLASSIFY_TEXT(\n",
    "    insight, \n",
    "    (SELECT ARRAY_AGG(plant_name) WITHIN GROUP (ORDER BY plant_name ASC) FROM vegetable_details) -- ASSEMBLE CATEGORIES\n",
    "):label::STRING\n",
    "WHERE insight IS NOT NULL \n",
    "AND insight <> '';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6117b30-f9cc-4426-871d-8ebbc2a215de",
   "metadata": {
    "collapsed": false,
    "name": "cell34"
   },
   "source": [
    "### Check your work. ðŸ¥‹\n",
    "\n",
    "**129** rows should have been **updated** in your knowledge base table. Take a look at the data in the table now.\n",
    "\n",
    "- Run the following query to return all rows from the knowledge base table.\n",
    "\n",
    "- Confirm that the **PLANT_NAME** column is now populated for **ALL** rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf7c08-c3d9-4842-8461-3b79f1d5e47e",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell35"
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM vegetable_knowledge_base;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e503ea-0eb1-4017-ac0c-9e09d5a56d0b",
   "metadata": {
    "collapsed": false,
    "name": "analyze_your_knowledge_base_data"
   },
   "source": [
    "## Analyze Your Knowledge Base Data ðŸ““\n",
    "\n",
    "With the knowledge base table loaded from the supplied PDF files and each row categorized according to plant name, it would be helpful to understand the distribution of this data.\n",
    "\n",
    "- How many \"factoids\" do we have per plant? \n",
    "\n",
    "- Do we have more information on some plants than others?\n",
    "\n",
    "- Are we missing data for some of our plant collection?\n",
    "\n",
    "All of this is useful to know to help us prioritize our efforts to expand this knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905b845-cce5-4daf-adc8-a77e3ea1c6d9",
   "metadata": {
    "collapsed": false,
    "name": "cell37"
   },
   "source": [
    "### Run an analytical query. ðŸ¥‹\n",
    "\n",
    "The following query is an example of one of the types of [JOIN](https://docs.snowflake.com/en/sql-reference/constructs/join) operations that Snowflake supports.\n",
    "\n",
    "In this, we want to get the full list of plant names from the **vegetable_details** table. For each plant, we want to produce a count of the number of rows in the **vegetable_knowledge_base** table. Using a `LEFT OUTER JOIN` means that even if there are no rows for a particular plant in **vegetable_knowledge_base**, we can still assign zero value to it - instead of it being omitted completely from the results.\n",
    "\n",
    "Run and review the following query to understand the count of articles per plant.\n",
    "\n",
    "ðŸ’¡ **Tip**:  We will name this cell, **knowledge_base_analytical_query**, in order easily reference its output later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d894f58-c153-4bfd-b16c-6d7664e19017",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "knowledge_base_analytical_query"
   },
   "outputs": [],
   "source": [
    "SELECT a.plant_name, \n",
    "       nvl(count(b.*),0) AS kb_article_count\n",
    "FROM vegetable_details a\n",
    "LEFT OUTER JOIN vegetable_knowledge_base b\n",
    "ON a.plant_name = b.plant_name\n",
    "GROUP BY a.plant_name\n",
    "ORDER BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3a12e-85a4-4f7c-8b39-ffd19bb06da3",
   "metadata": {
    "collapsed": false,
    "name": "streamlit_in_snowflake"
   },
   "source": [
    "## Streamlit in Snowflake ðŸ““\n",
    "\n",
    "[Streamlit](https://streamlit.io/) is an open-source Python library that makes it easy to create and share custom web apps for machine learning and data science.\n",
    "\n",
    "[Streamlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit) is an implementation of this technology on the Snowflake AI Data Cloud. \n",
    "\n",
    "- Snowflake manages the underlying compute and storage for Streamlit apps.\n",
    "\n",
    "- Streamlit apps are Snowflake objects and use Role-based Access Control (RBAC) to manage access to Streamlit apps.\n",
    "\n",
    "- Streamlit apps run on Snowflake warehouses and use internal stages to store files and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653942a3-38a6-4dce-8869-aadf2e295f97",
   "metadata": {
    "collapsed": false,
    "name": "cell40"
   },
   "source": [
    "### Visualize data with Streamlit. ðŸ¥‹\n",
    "\n",
    "One of the great strengths of Streamlit is the ease with which it allows you to interact with and visualize data. You have already used it in the **Quiz** sections at the end of each lab in this course. With just a few lines of Python code, you can create clean and compelling charts and graphs that bring your data to life.\n",
    "\n",
    "Run the following Python cell to produce a Streamlit bar chart that visualizes the results of the analytical query just run. Note how few lines of code are required to create this chart.\n",
    "\n",
    "- Which plants lack knowledge base articles?\n",
    "\n",
    "- Which plants have the most?\n",
    "\n",
    "ðŸ’¡ **Tip**: As you learned earlier in this course, you can reference the results of previous cells in a later cell in a Snowflake notebook. The following code uses this capability, drawing on the output from the analytical SQL query cell (**knowledge_base_analytical_query**) just executed, to create a **pandas** DataFrame, which is then passed into Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f9c86-efc0-40a4-964e-e0e7f1516011",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell41"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "chart_data = knowledge_base_analytical_query.to_pandas() # UTILIZES OUTPUT FROM AN EARLIER SQL CELL !!!\n",
    "\n",
    "st.header(\"Knowledge Base Articles Per Plant\")\n",
    "st.bar_chart(chart_data, x=\"PLANT_NAME\", y=\"KB_ARTICLE_COUNT\", color=['#33C4FF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6f695-8601-4298-88d6-f22179c7894b",
   "metadata": {
    "collapsed": false,
    "name": "theres_a_lot_more_to_snowflake_ai"
   },
   "source": [
    "## There's a Lot More to Snowflake AI and LLM Functions ðŸ““\n",
    "\n",
    "There's a lot more to know about Snowflake's AI (and ML!) capabilities and much more than we could cover in this course. \n",
    "\n",
    "However, a couple of task-specific Cortex LLM functions that are useful are `TRANSLATE()` and `SUMMARIZE()`. Let's take a quick look at these:\n",
    "\n",
    "- [TRANSLATE()](https://docs.snowflake.com/en/sql-reference/functions/translate-snowflake-cortex) - translates the given input text from one supported language to another.\n",
    "\n",
    "- [SUMMARIZE()](https://docs.snowflake.com/en/sql-reference/functions/summarize-snowflake-cortex) - summarizes the given English-language input text.\n",
    "\n",
    "Let's take a look at a couple of quick examples, utilizing our knowledge base data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a975b-0d07-4a55-bcf3-ab4adcc058db",
   "metadata": {
    "collapsed": false,
    "name": "cell43"
   },
   "source": [
    "### Run a `TRANSLATE()` example. ðŸ¥‹ \n",
    "\n",
    "As you saw in previous examples, accessing the Cortex LLM functions using SQL is straightforward. We can call `TRANSLATE()` as we would any other SQL function, providing the following inputs:\n",
    "\n",
    "- A string containing the text to be translated.\n",
    "\n",
    "- A string specifying the language code for the language the text is currently in. Options include French, German, Italian, Japanese, Korean, Spanish, and more.\n",
    "\n",
    "- A string specifying the language code into which the text should be translated.\n",
    "\n",
    "**Run** the following example code to translate information in the knowledge base for any plants whose name begins with `'C'` from **English** into **Spanish** and then back into **English** from that translated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110287b3-0bb0-4adc-aa21-636068e97631",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "SELECT plant_name, \n",
    "       insight AS original_english_text,\n",
    "       SNOWFLAKE.CORTEX.TRANSLATE(original_english_text, 'en', 'es') AS spanish_text,\n",
    "       SNOWFLAKE.CORTEX.TRANSLATE(spanish_text, 'es', 'en') AS english_text_from_spanish,\n",
    "FROM vegetable_knowledge_base\n",
    "WHERE LEFT(plant_name,1) = 'C'; -- all the plant names beginning with C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0947a24-9ebd-4b77-93c5-683f70deee5a",
   "metadata": {
    "collapsed": false,
    "name": "cell45"
   },
   "source": [
    "### Run a `SUMMARIZE()` example. ðŸ¥‹ \n",
    "\n",
    "As its name suggests, the `SUMMARIZE()` function generates a summary, and this is of the given English-language input text. It takes just one parameter, and this is a string of the text you want summarized. \n",
    "\n",
    "**Run** the following example, which focuses on a single plant from our collection, the **Pumpkin**:\n",
    "\n",
    "- We use [LISTAGG](https://docs.snowflake.com/en/sql-reference/functions/listagg) to bring together all the \"factoids\" (insights) we have for this plant as a single body of text.\n",
    "\n",
    "- `SUMMARIZE()` is run across this single body of text, from which a summary is generated.\n",
    "\n",
    "- We employ a Cortex LLM helper function [COUNT_TOKENS()](https://docs.snowflake.com/en/sql-reference/functions/count_tokens-snowflake-cortex) to indicate the relative size of the text **before** and **after** summarization - but you can, of course, review the outputs yourself.\n",
    "\n",
    "ðŸ’¡ **Tip**: A token is the smallest unit of text processed by Snowflake Cortex LLM functions, approximately equal to four characters. The equivalence of raw input or output text to tokens can vary by model.\n",
    "\n",
    "Go ahead and run the following code, and review the output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea37874-51af-4579-86e9-1bc117e839cf",
   "metadata": {
    "language": "sql",
    "name": "cell46"
   },
   "outputs": [],
   "source": [
    "SELECT listagg(insight) AS all_insights,\n",
    "        SNOWFLAKE.CORTEX.count_tokens('summarize', all_insights) AS all_insights_tokens,\n",
    "        SNOWFLAKE.CORTEX.SUMMARIZE(listagg(insight)) AS summary,\n",
    "        SNOWFLAKE.CORTEX.count_tokens('summarize', summary) AS summary_tokens\n",
    "FROM vegetable_knowledge_base\n",
    "WHERE plant_name = 'Pumpkin';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ead17-c249-40b3-b595-56fd0ed750ad",
   "metadata": {
    "collapsed": false,
    "name": "last_but_not_least_complete"
   },
   "source": [
    "## Last But Not Least, `COMPLETE()` ðŸ¥‹\n",
    "\n",
    "The most sophisticated of the Cortex LLM functions is [COMPLETE](https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex). In its simplest form, the function takes a **prompt** (text and instructions on what we would like done with that text) and generates a **response** (completion) using your choice of supported language model.\n",
    "\n",
    "To get a sense of how this works take a look at the following example:\n",
    "\n",
    "- Here we make use of the **snowflake-arctic** model.\n",
    "\n",
    "- We provide instructions to the model to help shape its response (e.g. \"You are an I.T expert\").\n",
    "\n",
    "- We pose a question (e.g., \"Explain what Snowflake is\").\n",
    "\n",
    "- The model's response will be based on its **innate** knowledge - that is, the data on which it has been trained - not additional information that we provide.\n",
    "\n",
    "Run the following code, and review the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e35a8-7b1c-4016-8411-24140ce5f913",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell48"
   },
   "outputs": [],
   "source": [
    "SELECT SNOWFLAKE.CORTEX.COMPLETE('snowflake-arctic', 'You are an I.T expert. Explain what Snowflake is.') AS complete_response;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e931e-c97e-442f-9ee3-071e765e2268",
   "metadata": {
    "collapsed": false,
    "name": "cell49"
   },
   "source": [
    "### Use our knowledge base data with `COMPLETE()` ðŸ¥‹\n",
    "\n",
    "For our final example, let's aggregate **ALL** of the garden and plant insights we have in our knowledge base and pose questions which we want `COMPLETE()` to generate answers to, based on this information. \n",
    "\n",
    "### The `COMPLETE()` query explained.\n",
    "\n",
    "The following query may look a little intimidating, so let's break it down into its part and explain what's happening:\n",
    "\n",
    "#### Section one\n",
    "\n",
    "- The first section contains sample questions for you to run.\n",
    "\n",
    "- Uncomment one each time you execute this SQL cell to ask a new question.\n",
    "\n",
    "- Note that these queries may take a little time to run - please be patient.\n",
    "\n",
    "![Complete query section 1 (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_complete_query_1.png)\n",
    "\n",
    "#### Section two\n",
    "\n",
    "- In the second section we define the prompt - which is our instructions and our ask of model accessed via the `COMPLETE()` function.\n",
    "\n",
    "- Note that we have included tags in the prompt to clearly identify different blocks of text within the prompt for the model's \"consumption\".\n",
    "\n",
    "![Complete query section 2 (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_complete_query_2.png)\n",
    "\n",
    "#### Section three\n",
    "\n",
    "- The third section is the actual call to the Cortex function.\n",
    "\n",
    "- Note that we make use of the variables defined earlier in the cell, which makes it more flexible to iterate on.\n",
    "\n",
    "![Complete query section 3 (image)](https://edu-cdev-images.s3.us-west-2.amazonaws.com/ob/ob_complete_query_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee70386-ea19-4238-a251-12a8b8fc6fe2",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "cell50"
   },
   "outputs": [],
   "source": [
    "-- example questions \n",
    "SET my_question  = 'which plant would take the shortest amount of time to cook'; -- should take around 30 seconds to complete                                    \n",
    "--SET my_question  = 'which plants are best for beginner gardeners'; -- should take around 60 seconds to complete \n",
    "\n",
    "\n",
    "-- the prompt\n",
    "SET prompt = 'You are a helpful gardening expert. Use only the supplied information <information> to answer the question posed <question>' || \n",
    "              $my_question || '</question> ' ||                 \n",
    "             ' If you have no supplied information do not answer'; \n",
    "                \n",
    "-- the Cortex function call\n",
    "SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "    'mixtral-8x7b', --32K context window\n",
    "    $my_question || \n",
    "    '<information>' ||\n",
    "    (SELECT LISTAGG(insight, ' ') FROM vegetable_knowledge_base) ||\n",
    "    '</information>'\n",
    ") AS cortex_output;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e66828-1700-4b67-8a05-126f0f94ac4a",
   "metadata": {
    "collapsed": false,
    "name": "final_quiz"
   },
   "source": [
    "## FINAL QUIZ :mag_right:\n",
    "\n",
    "## Test Your Knowledge. :memo: :mag_right:\n",
    "\n",
    "- Run the following Python cell to present a Streamlit-driven widget and answer the questions presented.\n",
    "\n",
    "- These questions may be on any content you have covered in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fedbdc7-f92e-4d47-ad11-e29263217d95",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell52"
   },
   "outputs": [],
   "source": [
    "st.divider()\n",
    "question = \"If you run a SELECT statement that has worked in the past, but now you get an error message saying the table doesn't exist, what should you check?\"\n",
    "options = [\"Pick selection below...\",\n",
    "           \"A) Your cloud provider\", \n",
    "           \"B) Your current region\", \n",
    "           \"C) Your context role\",\n",
    "           \"D) Your context warehouse\",\n",
    "           \"E) The role under your name in the lower left corner\"]\n",
    "\n",
    "user_answer = st.radio(question, options, index=0)\n",
    "if user_answer:\n",
    "    if user_answer == \"Pick selection below...\":\n",
    "        ''\n",
    "    else:\n",
    "        answer = '3b8a20f4bd738cffb2a64245be8c965e'\n",
    "        response = session.sql(f\"call common_db.resources.quiz_temp('{answer}', '{user_answer}', 'False')\").collect()\n",
    "        if response:\n",
    "            value = response[0]['QUIZ_TEMP']\n",
    "        st.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ce42d-dba7-4250-aad5-4fd308dfbf16",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell53"
   },
   "outputs": [],
   "source": [
    "st.divider()\n",
    "question = \"Which of these objects has the most compute power?\"\n",
    "options = [\"Pick selection below...\",\n",
    "           \"A) A Snowflake Database\", \n",
    "           \"B) A Snowflake Schema\", \n",
    "           \"C) A Snowflake Sequence\",\n",
    "           \"D) A Snowflake Warehouse\",\n",
    "           \"E) A Snowflake Data Mart\"]\n",
    "\n",
    "user_answer = st.radio(question, options, index=0)\n",
    "if user_answer:\n",
    "    if user_answer == \"Pick selection below...\":\n",
    "        ''\n",
    "    else:\n",
    "        answer = 'be8705c6c5c768910d2d3f5fc18c0d71'\n",
    "        response = session.sql(f\"call common_db.resources.quiz_temp('{answer}', '{user_answer}', 'False')\").collect()\n",
    "        if response:\n",
    "            value = response[0]['QUIZ_TEMP']\n",
    "        st.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f53509-9fa4-440e-8900-9b40ccd29154",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell54"
   },
   "outputs": [],
   "source": [
    "st.divider()\n",
    "question = \"Which of these objects is the lowest in the storage container hierarchy?\"\n",
    "options = [\"Pick selection below...\",\n",
    "           \"A) A Snowflake Database\", \n",
    "           \"B) A Snowflake Schema\", \n",
    "           \"C) A Snowflake Region\",\n",
    "           \"D) A Snowflake Account\",\n",
    "           \"E) A Snowflake Table\"]\n",
    "\n",
    "user_answer = st.radio(question, options, index=0)\n",
    "if user_answer:\n",
    "    if user_answer == \"Pick selection below...\":\n",
    "        ''\n",
    "    else:\n",
    "        answer = '7007175e6b054e35103190a17252491a'\n",
    "        response = session.sql(f\"call common_db.resources.quiz_temp('{answer}', '{user_answer}', 'False')\").collect()\n",
    "        if response:\n",
    "            value = response[0]['QUIZ_TEMP']\n",
    "        st.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f7f9c-c2ff-4f58-8871-06e195cc727e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell55"
   },
   "outputs": [],
   "source": [
    "st.divider()\n",
    "question = \"Which of the statements below describes an external Stage in Snowflake?\"\n",
    "options = [\"Pick selection below...\",\n",
    "           \"A) A stage can be used as a counter to generate unique ids for each new row in a table. We assign a starting value and an increment\", \n",
    "           \"B) A stage allows us to group database tables. For this, we created three stages in the GARDEN_PLANTS database. One was named VEGGIES\", \n",
    "           \"C) A stage can provide a \\\"window\\\" between Snowflake and a cloud folder\"]                \n",
    "\n",
    "user_answer = st.radio(question, options, index=0)\n",
    "if user_answer:\n",
    "    if user_answer == \"Pick selection below...\":\n",
    "        ''\n",
    "    else:\n",
    "        answer = '082006e998ba3d0551d2373e3c12f842'\n",
    "        response = session.sql(f\"call common_db.resources.quiz_temp('{answer}', '{user_answer}', 'False')\").collect()\n",
    "        if response:\n",
    "            value = response[0]['QUIZ_TEMP']\n",
    "        st.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283259b-0a18-4a1d-8a2d-f0887cc3364c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell56"
   },
   "outputs": [],
   "source": [
    "st.divider()\n",
    "question = \"Which of the following is not a Snowflake Cortex LLM function?\"\n",
    "options = [\"Pick selection below...\",\n",
    "           \"A) TRANSLATE\", \n",
    "           \"B) SUMMARIZE\", \n",
    "           \"C) PARSE_DOCUMENT\", \n",
    "           \"D) COUNT_TOKENS\", \n",
    "           \"E) CONTENT\", \n",
    "           \"F) COMPLETE\"]                \n",
    "\n",
    "user_answer = st.radio(question, options, index=0)\n",
    "if user_answer:\n",
    "    if user_answer == \"Pick selection below...\":\n",
    "        ''\n",
    "    else:\n",
    "        answer = 'b71018c50689d88fc0f7aac8d3cbad47'\n",
    "        response = session.sql(f\"call common_db.resources.quiz_temp('{answer}', '{user_answer}', 'False')\").collect()\n",
    "        if response:\n",
    "            value = response[0]['QUIZ_TEMP']\n",
    "        st.write(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a056f6-79c1-4dbe-829c-de459a1fda09",
   "metadata": {
    "collapsed": false,
    "name": "congratulations"
   },
   "source": [
    "## Congratulations :tada: :confetti_ball:\n",
    "\n",
    "You have completed this course - well done!"
   ]
  }
 ]
}